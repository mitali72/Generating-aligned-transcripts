{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mitali72/Generating-aligned-transcripts/blob/main/Vakyansh.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "JDbn41hF--2F",
        "outputId": "62ebab85-dd20-48bd-dece-e1c300083b23"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting webrtcvad\n",
            "  Downloading webrtcvad-2.0.10.tar.gz (66 kB)\n",
            "\u001b[K     |████████████████████████████████| 66 kB 1.6 MB/s \n",
            "\u001b[?25hCollecting wave\n",
            "  Downloading Wave-0.0.2.zip (38 kB)\n",
            "Collecting pydub\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Collecting resemblyzer\n",
            "  Downloading Resemblyzer-0.1.1.dev0-py3-none-any.whl (15.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 15.7 MB 4.4 MB/s \n",
            "\u001b[?25hCollecting hdbscan\n",
            "  Downloading hdbscan-0.8.28.tar.gz (5.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.2 MB 45.4 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: scipy>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from resemblyzer) (1.7.3)\n",
            "Requirement already satisfied: numpy>=1.10.1 in /usr/local/lib/python3.7/dist-packages (from resemblyzer) (1.21.6)\n",
            "Collecting typing\n",
            "  Downloading typing-3.7.4.3.tar.gz (78 kB)\n",
            "\u001b[K     |████████████████████████████████| 78 kB 7.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: librosa>=0.6.1 in /usr/local/lib/python3.7/dist-packages (from resemblyzer) (0.8.1)\n",
            "Requirement already satisfied: torch>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from resemblyzer) (1.12.1+cu113)\n",
            "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from librosa>=0.6.1->resemblyzer) (1.0.2)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.7/dist-packages (from librosa>=0.6.1->resemblyzer) (1.1.0)\n",
            "Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa>=0.6.1->resemblyzer) (4.4.2)\n",
            "Requirement already satisfied: resampy>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from librosa>=0.6.1->resemblyzer) (0.4.0)\n",
            "Requirement already satisfied: numba>=0.43.0 in /usr/local/lib/python3.7/dist-packages (from librosa>=0.6.1->resemblyzer) (0.56.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from librosa>=0.6.1->resemblyzer) (21.3)\n",
            "Requirement already satisfied: soundfile>=0.10.2 in /usr/local/lib/python3.7/dist-packages (from librosa>=0.6.1->resemblyzer) (0.10.3.post1)\n",
            "Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa>=0.6.1->resemblyzer) (3.0.0)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.7/dist-packages (from librosa>=0.6.1->resemblyzer) (1.6.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->librosa>=0.6.1->resemblyzer) (4.12.0)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->librosa>=0.6.1->resemblyzer) (0.39.1)\n",
            "Requirement already satisfied: setuptools<60 in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->librosa>=0.6.1->resemblyzer) (57.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->librosa>=0.6.1->resemblyzer) (3.0.9)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa>=0.6.1->resemblyzer) (2.23.0)\n",
            "Requirement already satisfied: appdirs>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa>=0.6.1->resemblyzer) (1.4.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa>=0.6.1->resemblyzer) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa>=0.6.1->resemblyzer) (2022.6.15)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa>=0.6.1->resemblyzer) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa>=0.6.1->resemblyzer) (2.10)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn!=0.19.0,>=0.14.0->librosa>=0.6.1->resemblyzer) (3.1.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.7/dist-packages (from soundfile>=0.10.2->librosa>=0.6.1->resemblyzer) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.0->soundfile>=0.10.2->librosa>=0.6.1->resemblyzer) (2.21)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.0.1->resemblyzer) (4.1.1)\n",
            "Requirement already satisfied: cython>=0.27 in /usr/local/lib/python3.7/dist-packages (from hdbscan) (0.29.32)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->numba>=0.43.0->librosa>=0.6.1->resemblyzer) (3.8.1)\n",
            "Building wheels for collected packages: webrtcvad, wave, hdbscan, typing\n",
            "  Building wheel for webrtcvad (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for webrtcvad: filename=webrtcvad-2.0.10-cp37-cp37m-linux_x86_64.whl size=72377 sha256=7674766a4757f4c2774a15cfd7ecad27ff906bad8fae2509b54c0adcc555e511\n",
            "  Stored in directory: /root/.cache/pip/wheels/11/f9/67/a3158d131f57e1c0a7d8d966a707d4a2fb27567a4fe47723ad\n",
            "  Building wheel for wave (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wave: filename=Wave-0.0.2-py3-none-any.whl size=1240 sha256=3dc41d47bb56d1799c058252a6bf9e81d46b2906638d9a91c295aaf9f756d074\n",
            "  Stored in directory: /root/.cache/pip/wheels/25/e8/fe/458c7dac00c6abedad6380b9d0ef1a5cbc7c21807df1d30915\n",
            "  Building wheel for hdbscan (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for hdbscan: filename=hdbscan-0.8.28-cp37-cp37m-linux_x86_64.whl size=2340296 sha256=465e40c038c4c46bac3463f409054aafcc477cc0e7e117b74f4e789e6b1ad104\n",
            "  Stored in directory: /root/.cache/pip/wheels/6e/7a/5e/259ccc841c085fc41b99ef4a71e896b62f5161f2bc8a14c97a\n",
            "  Building wheel for typing (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for typing: filename=typing-3.7.4.3-py3-none-any.whl size=26325 sha256=1efecb8affcb39bbf5f40277a3d2e47f523eea1c39b312dff4ea4dda3d7c0feb\n",
            "  Stored in directory: /root/.cache/pip/wheels/35/f3/15/01aa6571f0a72ee6ae7b827c1491c37a1f72d686fd22b43b0e\n",
            "Successfully built webrtcvad wave hdbscan typing\n",
            "Installing collected packages: webrtcvad, typing, wave, resemblyzer, pydub, hdbscan\n",
            "Successfully installed hdbscan-0.8.28 pydub-0.25.1 resemblyzer-0.1.1.dev0 typing-3.7.4.3 wave-0.0.2 webrtcvad-2.0.10\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "typing"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install webrtcvad wave pydub resemblyzer hdbscan"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0NP4Y9Gp5mPr",
        "outputId": "a0879e1b-11c4-4fd1-fd15-bdf78d4408f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pjv_VF3-6i9y",
        "outputId": "1fb616d0-04e5-4eb2-a471-01e0e8835ffd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/drive/MyDrive/BTP/NewsOnAir.zip\n",
            "   creating: /content/NewsOnAir/Gujarati/\n",
            "  inflating: /content/NewsOnAir/Gujarati/NSD-Gujarati-Gujarati-1320-1330-202262213512.mp3  \n",
            "  inflating: /content/NewsOnAir/Gujarati/NSD-Gujarati-Gujarati-1320-1330-202274133759.mp3  \n",
            "  inflating: /content/NewsOnAir/Gujarati/NSD-Gujarati-Gujarati-0745-0755-20225481235.mp3  \n",
            "  inflating: /content/NewsOnAir/Gujarati/NSD-Gujarati-Gujarati-0745-0755-2022819250.mp3  \n",
            "  inflating: /content/NewsOnAir/Gujarati/NSD-Gujarati-Gujarati-0745-0755-20224148830.mp3  \n",
            "  inflating: /content/NewsOnAir/Gujarati/NSD-Gujarati-Gujarati-1320-1330-202276134830.mp3  \n",
            "  inflating: /content/NewsOnAir/Gujarati/NSD-Gujarati-Gujarati-1950-2000-20228520538.mp3  \n",
            "  inflating: /content/NewsOnAir/Gujarati/NSD-Gujarati-Gujarati-0745-0755-202282184951.mp3  \n",
            "  inflating: /content/NewsOnAir/Gujarati/NSD-Gujarati-Gujarati-0745-0755-202282781351.mp3  \n",
            "  inflating: /content/NewsOnAir/Gujarati/NSD-Gujarati-Gujarati-1950-2000-20228921348.mp3  \n",
            "   creating: /content/NewsOnAir/Marathi/\n",
            "  inflating: /content/NewsOnAir/Marathi/NSD-Marathi-Marathi-2115-2130-202282322715.mp3  \n",
            "  inflating: /content/NewsOnAir/Marathi/NSD-Marathi-Marathi-2115-2130-202273122155.mp3  \n",
            "  inflating: /content/NewsOnAir/Marathi/NSD-Marathi-Marathi-1330-1340-2022820165427.mp3  \n",
            "  inflating: /content/NewsOnAir/Marathi/NSD-Marathi-Marathi-0920-0930-2022811102851.mp3  \n",
            "  inflating: /content/NewsOnAir/Marathi/NSD-Marathi-Marathi-2115-2130-202282622184.mp3  \n",
            "  inflating: /content/NewsOnAir/Marathi/NSD-Marathi-Marathi-0920-0930-2022825101646.mp3  \n",
            "  inflating: /content/NewsOnAir/Marathi/NSD-Marathi-Marathi-0920-0930-2022827101211.mp3  \n",
            "  inflating: /content/NewsOnAir/Marathi/NSD-Marathi-Marathi-2115-2130-2022819221333.mp3  \n",
            "  inflating: /content/NewsOnAir/Marathi/NSD-Marathi-Marathi-0920-0930-202282095752.mp3  \n",
            "  inflating: /content/NewsOnAir/Marathi/NSD-Marathi-Marathi-1330-1340-2022827141845.mp3  \n"
          ]
        }
      ],
      "source": [
        "# Load sample data\n",
        "!unzip /content/drive/MyDrive/BTP/NewsOnAir.zip -d /content/NewsOnAir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fPXZAeyf0P2F"
      },
      "outputs": [],
      "source": [
        "# display(Audio(\"https://newsonair.gov.in/writereaddata/Bulletins_Audio/NSD/2022/Aug/NSD-Gujarati-Gujarati-0745-0755-202281981355.mp3\"))\n",
        "from IPython.display import Audio\n",
        "from IPython.display import display\n",
        "from pydub import AudioSegment\n",
        "import os\n",
        "\n",
        "# Convert all mp3 files to wav with 16kHz sampling rate\n",
        "mp3_folder = \"/content/NewsOnAir/\"\n",
        "wav_folder = \"/content/NewsOnAirWav\"\n",
        "!mkdir \"$wav_folder\"\n",
        "for root, dirs, files in os.walk(mp3_folder):\n",
        "  for audio_file in files:\n",
        "    audio_path = os.path.join(root,audio_file)\n",
        "    sound = AudioSegment.from_mp3(audio_path)\n",
        "    sound = sound.set_frame_rate(16000)\n",
        "    sound = sound.set_channels(1)\n",
        "    wav_dir = os.path.join(\"/content/NewsOnAirWav/\",audio_path.split(\"/\")[3])\n",
        "    if not os.path.exists(wav_dir):\n",
        "      os.mkdir(wav_dir)\n",
        "\n",
        "    sound.export(os.path.join(wav_dir,audio_path.split(\"/\")[-1][:-3]+\"wav\"), format=\"wav\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X57jyfnii8jt"
      },
      "source": [
        "# **VAD**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yuu-59khES1G"
      },
      "outputs": [],
      "source": [
        "import webrtcvad\n",
        "import contextlib\n",
        "import wave\n",
        "import collections\n",
        "import sys\n",
        "import os\n",
        "\n",
        "def read_wave(path):\n",
        "    \"\"\"Reads a .wav file.\n",
        "    Takes the path, and returns (PCM audio data, sample rate).\n",
        "    \"\"\"\n",
        "    with contextlib.closing(wave.open(path, 'rb')) as wf:\n",
        "        num_channels = wf.getnchannels()\n",
        "        assert num_channels == 1\n",
        "        sample_width = wf.getsampwidth()\n",
        "        assert sample_width == 2\n",
        "        sample_rate = wf.getframerate()\n",
        "        assert sample_rate in (8000, 16000, 32000, 48000)\n",
        "        pcm_data = wf.readframes(wf.getnframes())\n",
        "        return pcm_data, sample_rate\n",
        "\n",
        "\n",
        "def write_wave(path, audio, sample_rate):\n",
        "    \"\"\"Writes a .wav file.\n",
        "    Takes path, PCM audio data, and sample rate.\n",
        "    \"\"\"\n",
        "    with contextlib.closing(wave.open(path, 'wb')) as wf:\n",
        "        wf.setnchannels(1)\n",
        "        wf.setsampwidth(2)\n",
        "        wf.setframerate(sample_rate)\n",
        "        wf.writeframes(audio)\n",
        "\n",
        "\n",
        "class Frame(object):\n",
        "    \"\"\"Represents a \"frame\" of audio data.\"\"\"\n",
        "    def __init__(self, bytes, timestamp, duration):\n",
        "        self.bytes = bytes\n",
        "        self.timestamp = timestamp\n",
        "        self.duration = duration\n",
        "\n",
        "\n",
        "def frame_generator(frame_duration_ms, audio, sample_rate):\n",
        "    \"\"\"Generates audio frames from PCM audio data.\n",
        "    Takes the desired frame duration in milliseconds, the PCM data, and\n",
        "    the sample rate.\n",
        "    Yields Frames of the requested duration.\n",
        "    \"\"\"\n",
        "    n = int(sample_rate * (frame_duration_ms / 1000.0) * 2)\n",
        "    offset = 0\n",
        "    timestamp = 0.0\n",
        "    duration = (float(n) / sample_rate) / 2.0\n",
        "    while offset + n < len(audio):\n",
        "        yield Frame(audio[offset:offset + n], timestamp, duration)\n",
        "        timestamp += duration\n",
        "        offset += n\n",
        "\n",
        "\n",
        "def vad_collector(sample_rate, frame_duration_ms,\n",
        "                  padding_duration_ms, vad, frames):\n",
        "    \"\"\"Filters out non-voiced audio frames.\n",
        "    Given a webrtcvad.Vad and a source of audio frames, yields only\n",
        "    the voiced audio.\n",
        "    Uses a padded, sliding window algorithm over the audio frames.\n",
        "    When more than 90% of the frames in the window are voiced (as\n",
        "    reported by the VAD), the collector triggers and begins yielding\n",
        "    audio frames. Then the collector waits until 90% of the frames in\n",
        "    the window are unvoiced to detrigger.\n",
        "    The window is padded at the front and back to provide a small\n",
        "    amount of silence or the beginnings/endings of speech around the\n",
        "    voiced frames.\n",
        "    Arguments:\n",
        "    sample_rate - The audio sample rate, in Hz.\n",
        "    frame_duration_ms - The frame duration in milliseconds.\n",
        "    padding_duration_ms - The amount to pad the window, in milliseconds.\n",
        "    vad - An instance of webrtcvad.Vad.\n",
        "    frames - a source of audio frames (sequence or generator).\n",
        "    Returns: A generator that yields PCM audio data.\n",
        "    \"\"\"\n",
        "    num_padding_frames = int(padding_duration_ms / frame_duration_ms)\n",
        "    # We use a deque for our sliding window/ring buffer.\n",
        "    ring_buffer = collections.deque(maxlen=num_padding_frames)\n",
        "    # We have two states: TRIGGERED and NOTTRIGGERED. We start in the\n",
        "    # NOTTRIGGERED state.\n",
        "    triggered = False\n",
        "\n",
        "    voiced_frames = []\n",
        "    for frame in frames:\n",
        "        is_speech = vad.is_speech(frame.bytes, sample_rate)\n",
        "\n",
        "        # sys.stdout.write('1' if is_speech else '0')\n",
        "        if not triggered:\n",
        "            ring_buffer.append((frame, is_speech))\n",
        "            num_voiced = len([f for f, speech in ring_buffer if speech])\n",
        "            # If we're NOTTRIGGERED and more than 90% of the frames in\n",
        "            # the ring buffer are voiced frames, then enter the\n",
        "            # TRIGGERED state.\n",
        "            if num_voiced > 0.9 * ring_buffer.maxlen:\n",
        "                triggered = True\n",
        "                # sys.stdout.write('+(%s)' % (ring_buffer[0][0].timestamp,))\n",
        "                # We want to yield all the audio we see from now until\n",
        "                # we are NOTTRIGGERED, but we have to start with the\n",
        "                # audio that's already in the ring buffer.\n",
        "                for f, s in ring_buffer:\n",
        "                    voiced_frames.append(f)\n",
        "                ring_buffer.clear()\n",
        "        else:\n",
        "            # We're in the TRIGGERED state, so collect the audio data\n",
        "            # and add it to the ring buffer.\n",
        "            voiced_frames.append(frame)\n",
        "            ring_buffer.append((frame, is_speech))\n",
        "            num_unvoiced = len([f for f, speech in ring_buffer if not speech])\n",
        "            # If more than 90% of the frames in the ring buffer are\n",
        "            # unvoiced, then enter NOTTRIGGERED and yield whatever\n",
        "            # audio we've collected.\n",
        "            if num_unvoiced > 0.9 * ring_buffer.maxlen:\n",
        "                # sys.stdout.write('-(%s)' % (frame.timestamp + frame.duration))\n",
        "                triggered = False\n",
        "                yield b''.join([f.bytes for f in voiced_frames])\n",
        "                ring_buffer.clear()\n",
        "                voiced_frames = []\n",
        "    # if triggered:\n",
        "        # sys.stdout.write('-(%s)' % (frame.timestamp + frame.duration))\n",
        "    # sys.stdout.write('\\n')\n",
        "    # If we have any leftover voiced audio when we run out of input,\n",
        "    # yield it.\n",
        "    if voiced_frames:\n",
        "        yield b''.join([f.bytes for f in voiced_frames])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kDToDc4ngEJ2"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "# Save chunks after VAD\n",
        "def save_vad(segments, sample_rate,wav_file = \"\"):\n",
        "  \n",
        "  # chunk_snr = []\n",
        "  audio_name = Path(wav_file).stem\n",
        "  chunk_path = os.path.join('/content/NewsOnAirVAD',wav_file.split(\"/\")[3],audio_name)\n",
        "  Path(chunk_path).mkdir(parents = True,exist_ok=True)\n",
        "  for i, segment in enumerate(segments):\n",
        "    write_wave(os.path.join(chunk_path,'chunk-%002d.wav' % (i,)), segment, sample_rate)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gz_zVXBvGKLx"
      },
      "outputs": [],
      "source": [
        "\n",
        "for root, dirs, files in os.walk(wav_folder):\n",
        "  for audio_file in files:\n",
        "    audio_path = os.path.join(root,audio_file)\n",
        "    audio, sample_rate = read_wave(audio_path)\n",
        "    vad = webrtcvad.Vad(mode = 2)\n",
        "    frames = frame_generator(30, audio, sample_rate)\n",
        "    frames = list(frames)\n",
        "    # Voice chunks\n",
        "    segments = vad_collector(sample_rate, 30, 300, vad, frames)\n",
        "    save_vad(segments,sample_rate,audio_path)\n",
        "    # snr_passed,chunk_index = check_snr(segments)\n",
        "    # segment_names.append(os.path.join())\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Join chunks after VAD\n",
        "output = []\n",
        "vad_path = \"/content/NewsOnAirVAD/Gujarati/NSD-Gujarati-Gujarati-1320-1330-202282814554\"\n",
        "for chunk_name in sorted(os.listdir(vad_path)):\n",
        "  chunk_path = os.path.join(vad_path,chunk_name)\n",
        "  if len(output)>0:\n",
        "    output[0] += AudioSegment.from_file(chunk_path, format=\"wav\", sample_rate=16000)\n",
        "  else:\n",
        "    output.append(AudioSegment.from_file(chunk_path, format=\"wav\", sample_rate=16000))\n",
        "\n",
        "output[0].export(\"only_speech_guj554_webrtc.wav\",format = \"wav\")\n"
      ],
      "metadata": {
        "id": "0SKvahW0_7kO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ThMgaa_tFrLJ"
      },
      "source": [
        "# **SNR thresholding & Speaker Clustering** (Resemblyzer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DaLzTRpkjKMv"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def wada_snr(wav):\n",
        "    # Direct blind estimation of the SNR of a speech signal.\n",
        "    #\n",
        "    # Paper on WADA SNR:\n",
        "    #   http://www.cs.cmu.edu/~robust/Papers/KimSternIS08.pdf\n",
        "    #\n",
        "    # This function was adapted from this matlab code:\n",
        "    #   https://labrosa.ee.columbia.edu/projects/snreval/#9\n",
        "\n",
        "    # init\n",
        "    eps = 1e-10\n",
        "    # next 2 lines define a fancy curve derived from a gamma distribution -- see paper\n",
        "    db_vals = np.arange(-20, 101)\n",
        "    g_vals = np.array([0.40974774, 0.40986926, 0.40998566, 0.40969089, 0.40986186, 0.40999006, 0.41027138, 0.41052627, 0.41101024, 0.41143264, 0.41231718, 0.41337272, 0.41526426, 0.4178192 , 0.42077252, 0.42452799, 0.42918886, 0.43510373, 0.44234195, 0.45161485, 0.46221153, 0.47491647, 0.48883809, 0.50509236, 0.52353709, 0.54372088, 0.56532427, 0.58847532, 0.61346212, 0.63954496, 0.66750818, 0.69583724, 0.72454762, 0.75414799, 0.78323148, 0.81240985, 0.84219775, 0.87166406, 0.90030504, 0.92880418, 0.95655449, 0.9835349 , 1.01047155, 1.0362095 , 1.06136425, 1.08579312, 1.1094819 , 1.13277995, 1.15472826, 1.17627308, 1.19703503, 1.21671694, 1.23535898, 1.25364313, 1.27103891, 1.28718029, 1.30302865, 1.31839527, 1.33294817, 1.34700935, 1.3605727 , 1.37345513, 1.38577122, 1.39733504, 1.40856397, 1.41959619, 1.42983624, 1.43958467, 1.44902176, 1.45804831, 1.46669568, 1.47486938, 1.48269965, 1.49034339, 1.49748214, 1.50435106, 1.51076426, 1.51698915, 1.5229097 , 1.528578  , 1.53389835, 1.5391211 , 1.5439065 , 1.54858517, 1.55310776, 1.55744391, 1.56164927, 1.56566348, 1.56938671, 1.57307767, 1.57654764, 1.57980083, 1.58304129, 1.58602496, 1.58880681, 1.59162477, 1.5941969 , 1.59693155, 1.599446  , 1.60185011, 1.60408668, 1.60627134, 1.60826199, 1.61004547, 1.61192472, 1.61369656, 1.61534074, 1.61688905, 1.61838916, 1.61985374, 1.62135878, 1.62268119, 1.62390423, 1.62513143, 1.62632463, 1.6274027 , 1.62842767, 1.62945532, 1.6303307 , 1.63128026, 1.63204102])\n",
        "\n",
        "    # peak normalize, get magnitude, clip lower bound\n",
        "    wav = np.array(wav)\n",
        "    wav = wav / abs(wav).max()\n",
        "    abs_wav = abs(wav)\n",
        "    abs_wav[abs_wav < eps] = eps\n",
        "\n",
        "    # calcuate statistics\n",
        "    # E[|z|]\n",
        "    v1 = max(eps, abs_wav.mean())\n",
        "    # E[log|z|]\n",
        "    v2 = np.log(abs_wav).mean()\n",
        "    # log(E[|z|]) - E[log(|z|)]\n",
        "    v3 = np.log(v1) - v2\n",
        "\n",
        "    # table interpolation\n",
        "    wav_snr_idx = None\n",
        "    if any(g_vals < v3):\n",
        "        wav_snr_idx = np.where(g_vals < v3)[0].max()\n",
        "    # handle edge cases or interpolate\n",
        "    if wav_snr_idx is None:\n",
        "        wav_snr = db_vals[0]\n",
        "    elif wav_snr_idx == len(db_vals) - 1:\n",
        "        wav_snr = db_vals[-1]\n",
        "    else:\n",
        "        wav_snr = db_vals[wav_snr_idx] + \\\n",
        "            (v3-g_vals[wav_snr_idx]) / (g_vals[wav_snr_idx+1] - \\\n",
        "            g_vals[wav_snr_idx]) * (db_vals[wav_snr_idx+1] - db_vals[wav_snr_idx])\n",
        "\n",
        "    # Calculate SNR\n",
        "    dEng = sum(wav**2)\n",
        "    dFactor = 10**(wav_snr / 10)\n",
        "    dNoiseEng = dEng / (1 + dFactor) # Noise energy\n",
        "    dSigEng = dEng * dFactor / (1 + dFactor) # Signal energy\n",
        "    snr = 10 * np.log10(dSigEng / dNoiseEng)\n",
        "\n",
        "    return wav_snr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eaD0Ena0WQs5"
      },
      "outputs": [],
      "source": [
        "# Check SNR thresholds\n",
        "def check_snr(segments):\n",
        "  \"\"\"\n",
        "  segments: generator\n",
        "  \"\"\"\n",
        "  snr_passed = []\n",
        "  chunk_index = []\n",
        "  for i,segment in enumerate(segments):\n",
        "    chunk_snr = wada_snr(segment)\n",
        "    if chunk_snr>=20 or chunk_snr<=60:\n",
        "      snr_passed.append(segment)\n",
        "      chunk_index.append(i)\n",
        "\n",
        "  return snr_passed,chunk_index\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HvIkW4Gipnrn",
        "outputId": "70978221-e3ca-4611-ae4f-1d31148f9af2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded the voice encoder model on cpu in 0.05 seconds.\n"
          ]
        }
      ],
      "source": [
        "from resemblyzer import VoiceEncoder, preprocess_wav\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "from scipy.io import wavfile\n",
        "import csv\n",
        "\n",
        "\n",
        "encoder = VoiceEncoder()\n",
        "chunk_fields = [\"audio_name\", \"chunk_id\", \"snr\", \"len\"]\n",
        "vad_folder = \"/content/NewsOnAirVAD/\"\n",
        "\n",
        "f = open('chunk_info.csv', 'w')\n",
        "writer = csv.DictWriter(f, fieldnames = chunk_fields)\n",
        "writer.writeheader()\n",
        "embedv = []\n",
        "for root, dirs, files in os.walk(vad_folder):\n",
        "  chunk_info = {}\n",
        "  \n",
        "  for audio_file in sorted(files):\n",
        "    \n",
        "    audio_path = os.path.join(root,audio_file)\n",
        "    _,wav = wavfile.read(audio_path)\n",
        "    chunk_snr = wada_snr(wav)\n",
        "    embed = encoder.embed_utterance(preprocess_wav(audio_path))\n",
        "\n",
        "    chunk_info[\"audio_name\"] = audio_path.split(\"/\")[-2]\n",
        "    chunk_info[\"chunk_id\"] = Path(audio_file).stem[-2:]\n",
        "    chunk_info[\"snr\"] = chunk_snr\n",
        "    chunk_info[\"len\"] = len(wav)/16000\n",
        "    embedv.append(embed)\n",
        " \n",
        "    writer.writerow(chunk_info)\n",
        "\n",
        "f.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JpsnjnkNDjI_"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from ast import literal_eval\n",
        "import json\n",
        "\n",
        "\n",
        "df = pd.read_csv('chunk_info.csv')\n",
        "df[\"embed\"] = embedv\n",
        "snr_passed = df.loc[(df[\"snr\"]>=20) & (df[\"snr\"]<=60)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ptTUVvdXwl0m",
        "outputId": "88ec9773-7917-46d2-8e0a-964936e84417"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ]
        }
      ],
      "source": [
        "import hdbscan\n",
        "\n",
        "# Noisy samples given -1\n",
        "clusterer = hdbscan.HDBSCAN(min_cluster_size=4, allow_single_cluster=True, min_samples=2\n",
        "                            )\n",
        "cluster_labels = clusterer.fit_predict(np.stack(snr_passed[\"embed\"].values))\n",
        "snr_passed[\"cluster_label\"] = cluster_labels\n",
        "output = snr_passed.sort_values(by=['cluster_label','snr'], ascending=[True, False])\n",
        "output.to_csv(\"output.csv\", columns = [\"audio_name\", \"chunk_id\", \"snr\",\"cluster_label\"], index = False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}